{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73U6yPyZmhGL"
   },
   "source": [
    "# Sequence To SQL\n",
    "\n",
    "Welcome to our project in the Advanced Natural Language Processing course\n",
    "\n",
    "We try to build it with the data provided in https://github.com/salesforce/WikiSQL\n",
    "\n",
    "Remove this: https://towardsdatascience.com/text-to-sql-learning-to-query-tables-with-natural-language-7d714e60a70d?gi=6b6c7e91e298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPUHkkwhVukj",
    "outputId": "d365e360-6c44-4342-f1c7-c32ebe5c8bcc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print('Current device:', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print('Failed to find GPU. Will use CPU.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection and Review\n",
    "Clone the data from the WikiSQL git repository and install them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrMz3n3dbHlU"
   },
   "source": [
    "Take a look inside the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zR6cyK-UbFNV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_data_from_file(file: str):\n",
    "  ret_data = []\n",
    "  with open(file) as json_file:\n",
    "    while True:\n",
    "      # Get next line from file\n",
    "      line = json_file.readline()\n",
    "      if not line:\n",
    "        break\n",
    "\n",
    "      data = json.loads(line)\n",
    "      ret_data.append(data)\n",
    "  return ret_data\n",
    "\n",
    "def convert_to_id_dict(data, id_key: str):\n",
    "  ret_dict = {}\n",
    "  for element in data:\n",
    "    if id_key in element:\n",
    "      ret_dict[element[id_key]] = element\n",
    "    else:\n",
    "      print(f'Element {element} doenst contain key {id_key}')\n",
    "  return ret_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A80zkDsgqjE"
   },
   "source": [
    "Lets see if we succesfully serialized the data into objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sihMUsXg-yt",
    "outputId": "8317c04e-70bf-41bf-8f8c-c4ba39c5fd30"
   },
   "outputs": [],
   "source": [
    "data_folder = \"../data\"\n",
    "\n",
    "dev_req_data = read_json_data_from_file(f'{data_folder}/dev.jsonl')\n",
    "dev_table_data = read_json_data_from_file(f'{data_folder}/dev.tables.jsonl')\n",
    " \n",
    "print(f'We have {len(dev_req_data)} dev data with {len(dev_table_data)} tables.')\n",
    "print(f'An example Request: ')\n",
    "print(json.dumps(dev_req_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzjw8292zYcE"
   },
   "source": [
    "### The fields represent the following:\n",
    "\n",
    "* `phase`: the phase in which the dataset was collected. We collected WikiSQL in two phases.\n",
    "* `question`: the natural language question written by the worker.\n",
    "* `table_id`: the ID of the table to which this question is addressed.\n",
    "sql: the SQL query corresponding to the question. This has the following *subfields:\n",
    "  * `sel`: the numerical index of the column that is being selected. You can find the actual column from the table.\n",
    "  * `agg`: the numerical index of the aggregation operator that is being used. You can find the actual operator from Query.agg_ops in lib/query.py.\n",
    "  * `conds`: a list of triplets (column_index, operator_index, condition) where:\n",
    "    * `column_index`: the numerical index of the condition column that is being used. You can find the actual column from the table.\n",
    "    * `operator_index`: the numerical index of the condition operator that is being used. You can find the actual operator from Query.cond_ops in lib/query.py.\n",
    "    * `condition`: the comparison value for the condition, in either string or float type.\n",
    "\n",
    "\n",
    "## An example Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7vfdbCKGG3p",
    "outputId": "a2fb59ef-25a3-4d4f-d652-5f8f0d6b796d"
   },
   "outputs": [],
   "source": [
    "print(json.dumps(dev_table_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7i0WqeKz2Cy"
   },
   "source": [
    "## Preprocess\n",
    "\n",
    "The data is stored with indices but we need the actual column names so saturate the requests with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwsK8yDV2_yD"
   },
   "outputs": [],
   "source": [
    "# Transform the data into a dictonary index by the id\n",
    "dev_table_data_dict = convert_to_id_dict(dev_table_data, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIAcsIpd7OpY"
   },
   "outputs": [],
   "source": [
    "# Get the preliminary data\n",
    "# Maybe we want the other idexes also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rnvuug6C0kaK"
   },
   "outputs": [],
   "source": [
    "def get_table_column(data_list, tables_dict):\n",
    "  ret_list = []\n",
    "  for element in data_list:\n",
    "    current_table = tables_dict[element['table_id']]\n",
    "    columns = current_table['header']\n",
    "    # Replace the index\n",
    "    element['columns'] = columns\n",
    "    element['types'] = current_table['types']\n",
    "    element['sql']['sel'] = columns[element['sql']['sel']]\n",
    "\n",
    "    if 'page_title' in current_table:\n",
    "        element['table_name'] = current_table['page_title']\n",
    "    elif 'section_title' in current_table:\n",
    "        element['table_name'] = current_table['section_title']\n",
    "    elif 'caption' in current_table:\n",
    "        element['table_name'] = current_table['caption']\n",
    "    elif 'name' in current_table:\n",
    "        element['table_name'] = current_table['name']\n",
    "\n",
    "    # For the where conditions\n",
    "    for cond in element['sql']['conds']:\n",
    "      cond[0] = columns[cond[0]]\n",
    "    ret_list.append(element)\n",
    "  return ret_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Cv1VKePBUwf",
    "outputId": "5f52c637-26e3-47b1-c111-cd10b31d1494"
   },
   "outputs": [],
   "source": [
    "dev_req_data = read_json_data_from_file(f'{data_folder}/dev.jsonl')\n",
    "dev_table_data = read_json_data_from_file(f'{data_folder}/dev.tables.jsonl')\n",
    "\n",
    "dev_prep_req_data = get_table_column(dev_req_data, dev_table_data_dict)\n",
    "\n",
    "\n",
    "print(f'Filed in with the Columns: ')\n",
    "print(json.dumps(dev_prep_req_data[-2], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pad_max_length = 50\n",
    "\n",
    "def get_question_answers(request, tokenizer):\n",
    "    input_list = []\n",
    "\n",
    "    table_name = request['table_name'] #should be name not id\n",
    "    space_token = ' '\n",
    "    columns = request['columns']\n",
    "    req_question = request['question'] # might need to be tokenized\n",
    "    max_len = 0\n",
    "    for i, col in enumerate(columns):\n",
    "        col_type = request['types'][i] # infere type somehow\n",
    "        column_representation = col_type + space_token + table_name + space_token + col\n",
    "        embedding = tokenizer.encode_plus(\n",
    "            column_representation,\n",
    "            req_question,\n",
    "            add_special_tokens=True,\n",
    "        )\n",
    "        if max_len < len(embedding['input_ids']):\n",
    "            max_len = len(embedding['input_ids'])\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        col_type = request['types'][i] # infere type somehow\n",
    "        column_representation = col_type + space_token + table_name + space_token + col\n",
    "        embedding = tokenizer.encode_plus(\n",
    "            column_representation,\n",
    "            req_question,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding=True,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "        input_list.append(embedding)\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pad_max_length = 50\n",
    "def get_question_answers(request, tokenizer):\n",
    "    input_list = []\n",
    "\n",
    "    table_name = request['table_name'] #should be name not id\n",
    "    space_token = ' '\n",
    "    columns = request['columns']\n",
    "    req_question = request['question'] # might need to be tokenized\n",
    "    for i, col in enumerate(columns):\n",
    "        col_type = request['types'][i] # infere type somehow\n",
    "        column_representation = col_type + space_token + table_name + space_token + col\n",
    "        embedding = tokenizer.encode_plus(\n",
    "            column_representation,\n",
    "            req_question,\n",
    "            add_special_tokens=True,\n",
    "            max_length=pad_max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "        input_list.append(embedding)\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCnTnkOXH66r"
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ndN0Emuk2K-"
   },
   "source": [
    "In this section, we will look into **contextual embeddings**. \n",
    "\n",
    "For this we use [**pretrained BERT**](https://www.aclweb.org/anthology/N19-1423.pdf) provided via [HuggingFace](https://huggingface.co/).\n",
    "\n",
    "Let's first install the HuggingFace python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dp imports here\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyLYVYNrC7Pl",
    "outputId": "827654c5-31a4-4e57-c9ef-4760e5cf20eb"
   },
   "outputs": [],
   "source": [
    "print(dev_prep_req_data[0])\n",
    "for tokens in get_question_answers(dev_prep_req_data[0], tokenizer):\n",
    "    print(tokens)\n",
    "    print(tokenizer.convert_ids_to_tokens(tokens['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generall model configuration\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "sep_token = tokenizer.sep_token\n",
    "cls_token = tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeujv-VJIHGy"
   },
   "outputs": [],
   "source": [
    "# reference is hydranet https://arxiv.org/pdf/2008.04759.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for data in dev_prep_req_data:\n",
    "    c_split_data = tokenizer.tokenize(data['question'])\n",
    "    for line in c_split_data:\n",
    "        tokens = tokenizer.encode(line, max_length=512)\n",
    "        token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_qge_QPAGDN",
    "outputId": "e00d40a4-b2c2-4e25-817a-720fb3e5f179"
   },
   "outputs": [],
   "source": [
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 50]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "req_embeddings = get_question_answers(dev_prep_req_data[0], tokenizer)\n",
    "print(req_embeddings)\n",
    "input_ids = [req_embedding['input_ids'] for req_embedding in req_embeddings]\n",
    "token_type_ids = [req_embedding['token_type_ids'] for req_embedding in req_embeddings]\n",
    "attention_mask = [req_embedding['attention_mask'] for req_embedding in req_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(input_ids)\n",
    "print(token_type_ids)\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "    input_ids=torch.tensor(input_ids), # The tokens representing our input text.\n",
    "    attention_mask=torch.tensor(attention_mask),\n",
    "    token_type_ids=torch.tensor(token_type_ids)\n",
    ") # The segment IDs to differentiate question from answer_text\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'last hidden state  : {outputs.last_hidden_state.shape}')\n",
    "print(f'pooled output layer: {outputs.pooler_output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "linear = nn.Linear(model.config.hidden_size, 6)\n",
    "\n",
    "linear(outputs.pooler_output)\n",
    "F.softmax(linear(outputs.pooler_output), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "answer_start = torch.argmax(outputs.start_logits)\n",
    "answer_end = torch.argmax(outputs.end_logits)\n",
    "\n",
    "text = tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])\n",
    "\n",
    "print(f'{text}: {answer_start} {answer_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ANLP_Project_SeqToSQL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
